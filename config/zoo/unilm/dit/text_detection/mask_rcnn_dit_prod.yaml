_BASE_: "./Base-RCNN-FPN.yaml"
MODEL:
  PIXEL_MEAN: [ 127.5, 127.5, 127.5 ]
  PIXEL_STD: [ 127.5, 127.5, 127.5 ]
  # Path relative to model zoo root directory (default __model_path__)
#  WEIGHTS: "unilm/dit/text_detection/paper-tuned-184/model_0001999.pth-1600.pth" # GOOD
#  WEIGHTS: "unilm/dit/text_detection/tuned-2500-LARGE-v5/model_0053999.pth" # GOOD
#  WEIGHTS: "unilm/dit/text_detection/tuned-4000-LARGE/model_0095999.pth" # GOOD- IN PROD AS OF 04/08/2024
#  WEIGHTS: "unilm/dit/text_detection/tuned-4000-LARGE-04082024/model_0109999.pth" # GOOD
#  WEIGHTS: "unilm/dit/text_detection/tuned-4000-LARGE-04082024/model_0145999.pth" # 04-11-2024
#  WEIGHTS: "unilm/dit/text_detection/tuned-4000-LARGE-04082024/model_0155999.pth" # 04-16-2024
  WEIGHTS: "unilm/dit/text_detection/tuned-4000-20240524-001/model_0147999.pth" # 05-30-2024

  VIT:
    NAME: "dit_large_patch16"
    OUT_FEATURES: [ "layer7", "layer11", "layer15", "layer23" ]
    DROP_PATH: 0.2
  FPN:
    IN_FEATURES: [ "layer7", "layer11", "layer15", "layer23" ]
  ANCHOR_GENERATOR:
    SIZES: [[4], [8], [16], [32], [64]]
    ASPECT_RATIOS: [[1.5, 3.5, 6.5]]
SOLVER:
  WARMUP_ITERS: 1000
  IMS_PER_BATCH: 8
  MAX_ITER: 60000
  CHECKPOINT_PERIOD: 1000
  BASE_LR: 0.00005
  AMP:
    ENABLED: True
TEST:
  EVAL_PERIOD: 1000
  DETECTIONS_PER_IMAGE: 2500
OUTPUT_DIR: $AMLT_OUTPUT_DIR

# Adjust the following parameters to fit your needs
INPUT:
  MAX_SIZE_TEST: 4000
  MAX_SIZE_TRAIN: 4000

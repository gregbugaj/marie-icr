"use strict";(self.webpackChunkmare_ai=self.webpackChunkmare_ai||[]).push([[152],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>m});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},u=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,l=e.originalType,s=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),d=p(n),m=i,h=d["".concat(s,".").concat(m)]||d[m]||c[m]||l;return n?a.createElement(h,r(r({ref:t},u),{},{components:n})):a.createElement(h,r({ref:t},u))}));function m(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var l=n.length,r=new Array(l);r[0]=d;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:i,r[1]=o;for(var p=2;p<l;p++)r[p]=n[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},681:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>r,default:()=>c,frontMatter:()=>l,metadata:()=>o,toc:()=>p});var a=n(7462),i=(n(7294),n(3905));const l={sidebar_position:1},r="Installation",o={unversionedId:"getting-started/installation",id:"getting-started/installation",title:"Installation",description:"Prerequisites",source:"@site/docs/getting-started/installation.md",sourceDirName:"getting-started",slug:"/getting-started/installation",permalink:"/docs/getting-started/installation",draft:!1,editUrl:"https://github.com/gregbugaj/marie-ai/tree/develop/docs/docs/getting-started/installation.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Getting Started",permalink:"/docs/category/getting-started"},next:{title:"Troubleshooting",permalink:"/docs/getting-started/troubleshooting"}},s={},p=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Environment Setup",id:"environment-setup",level:2},{value:"Setup Python 3.10",id:"setup-python-310",level:3},{value:"Install Pytorch 2.0",id:"install-pytorch-20",level:3},{value:"Using a Python virtual environment",id:"using-a-python-virtual-environment",level:2},{value:"Using Conda",id:"using-conda",level:2},{value:"Verify Pytorch Install",id:"verify-pytorch-install",level:3},{value:"Installation Steps",id:"installation-steps",level:2},{value:"From source",id:"from-source",level:3},{value:"Additional dependencies",id:"additional-dependencies",level:3},{value:"Marie-AI as a dependency",id:"marie-ai-as-a-dependency",level:3},{value:"Verify the installation",id:"verify-the-installation",level:3},{value:"Docker image",id:"docker-image",level:2},{value:"Docker on CPU-only platforms",id:"docker-on-cpu-only-platforms",level:2},{value:"Building container",id:"building-container",level:3},{value:"Docker with GPU Support",id:"docker-with-gpu-support",level:2},{value:"Inference on the GPU",id:"inference-on-the-gpu",level:3},{value:"Building container",id:"building-container-1",level:3},{value:"Container maintenance",id:"container-maintenance",level:2},{value:"Useful docker commands",id:"useful-docker-commands",level:3},{value:"Common issues",id:"common-issues",level:2},{value:"Segmentation fault",id:"segmentation-fault",level:3},{value:"Missing convert_namespace_to_omegaconf",id:"missing-convert_namespace_to_omegaconf",level:3},{value:"<code>distutils</code> has no attribute version",id:"distutils-has-no-attribute-version",level:3},{value:"CUDA capability sm_86 is not compatible with the current PyTorch installation",id:"cuda-capability-sm_86-is-not-compatible-with-the-current-pytorch-installation",level:3},{value:"References",id:"references",level:3}],u={toc:p};function c(e){let{components:t,...n}=e;return(0,i.kt)("wrapper",(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"installation"},"Installation"),(0,i.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Linux"),(0,i.kt)("li",{parentName:"ul"},"Python 3.10"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://pytorch.org/get-started/locally/"},"Pytorch torch-2.0.0.XXXXXXXXXX+cu118")," "),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://developer.nvidia.com/cuda-11-8-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=22.04&target_type=deb_local"},"CUDA 11.8")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html"},"cuDNN 8.7.0"))),(0,i.kt)("h2",{id:"environment-setup"},"Environment Setup"),(0,i.kt)("p",null,"Setup development environment for Marie-AI. We recommend using Python 3.10.\nThere are known issues with upstream packages as they are not yet compatible with Python 3.11."),(0,i.kt)("h3",{id:"setup-python-310"},"Setup Python 3.10"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"sudo apt-get install python3.10\n")),(0,i.kt)("p",null,"From inside this directory, create a virtual environment using the Python venv module:"),(0,i.kt)("p",null,"Here we will add third-party repository for Python 3.10 on Ubuntu 20.04"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"sudo apt install software-properties-common -y\nsudo add-apt-repository ppa:deadsnakes/ppa\n")),(0,i.kt)("p",null,"On Ubuntu 22.04 you can use the following command to install Python 3.10"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"sudo apt-get update\nsudo apt install python3.10\nsudo apt install python3.10-dev\nsudo apt install python3-virtualenv\nsudo apt install python3.10-venv\npython3.10 -m venv .env\n")),(0,i.kt)("admonition",{type:"note"},(0,i.kt)("p",{parentName:"admonition"},"If you are experienced with PyTorch and have already installed it, just skip this part and jump to the next section. Otherwise, you can follow ",(0,i.kt)("a",{parentName:"p",href:"#installation-steps"},"these steps")," for the preparation.")),(0,i.kt)("h3",{id:"install-pytorch-20"},"Install Pytorch 2.0"),(0,i.kt)("p",null,"The following command will install PyTorch 2.0 with CUDA 11.8 support.\nIf you want to install PyTorch without CUDA support, you can remove the ",(0,i.kt)("inlineCode",{parentName:"p"},"cu118")," part from the command."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"pip3 install --pre torch[dynamo] torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cu118 --force\n")),(0,i.kt)("h2",{id:"using-a-python-virtual-environment"},"Using a Python virtual environment"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"mkdir ~/marie-ai\ncd ~/marie-ai\n")),(0,i.kt)("p",null,"Alternatively you can have shared virtual environment"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"python3 -m venv ~/environment/marie\n")),(0,i.kt)("p",null,"This will require you to create a link a sympolic link ",(0,i.kt)("inlineCode",{parentName:"p"},".env ")," that point to the real environment ",(0,i.kt)("inlineCode",{parentName:"p"},"~/environment/marie")),(0,i.kt)("p",null,"You can jump in and out of your virtual environment with the ",(0,i.kt)("inlineCode",{parentName:"p"},"activate")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"deactivate")," scripts:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"# Activate the virtual environment\nsource .env/bin/activate\n\n# Deactivate the virtual environment\nsource .env/bin/deactivate\n")),(0,i.kt)("h2",{id:"using-conda"},"Using Conda"),(0,i.kt)("p",null,"TODO : conda have not been tested but in should work."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"conda create -n pytorch python=3.10\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"conda activate pytorch\n")),(0,i.kt)("h3",{id:"verify-pytorch-install"},"Verify Pytorch Install"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},'python -c "import torch; print(torch.__version__)"\n')),(0,i.kt)("h2",{id:"installation-steps"},"Installation Steps"),(0,i.kt)("p",null,"There are number of different ways that this project can be setup."),(0,i.kt)("h3",{id:"from-source"},"From source"),(0,i.kt)("p",null,"If you wish to run and develop ",(0,i.kt)("inlineCode",{parentName:"p"},"Marie-AI")," directly, install it from source:"),(0,i.kt)("p",null,"First install required build dependencies, if they are not present."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"sudo apt-get install libpq-dev python-dev-is-python3\n")),(0,i.kt)("p",null,"Install ONNX Runtime from source ","[https://onnxruntime.ai/docs/build/inferencing.html]"," :"),(0,i.kt)("p",null,"Create the wheel file and install it :"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"}," ./build.sh --config Release --build_shared_lib --parallel --build_wheel\n\n ./build.sh --config Release --build_wheel --enable_pybind --parallel --skip_tests --build_shared_lib\n")),(0,i.kt)("p",null,"Next install from source :"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},'git clone https://github.com/marieai/marie-ai.git\ncd marie-ai\ngit checkout develop\n\n# "-v" increases pip\'s verbosity.\n# "-e" means installing the project in editable mode,\n# That is, any local modifications on the code will take effect immediately\n\npip install  Cython\npip install pybind11\n\npip install -r requirements.txt\npip install -v -e .\n\n')),(0,i.kt)("h3",{id:"additional-dependencies"},"Additional dependencies"),(0,i.kt)("p",null,"FVCore install"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"python3 -m pip install -U 'git+https://github.com/facebookresearch/fvcore'\n")),(0,i.kt)("p",null,"Fairseq install"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"git clone https://github.com/pytorch/fairseq.git\ncd fairseq \npython setup.py build install\n")),(0,i.kt)("p",null,"Detectron2 install "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n# Or, to install it from a local clone:\ngit clone https://github.com/facebookresearch/detectron2.git\npython -m pip install -e detectron2\n\n")),(0,i.kt)("p",null,"Common Installation Issues"),(0,i.kt)("p",null,"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfairseq 0.12.2 requires hydra-core<1.1,>=1.0.7, but you have hydra-core 1.2.0 which is incompatible.\nfairseq 0.12.2 requires omegaconf<2.1, but you have omegaconf 2.2.3 which is incompatible."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"}," pip uninstall hydra-core\n pip uninstall omegacon\n pip uninstall fairseq\n")),(0,i.kt)("p",null,"Install ",(0,i.kt)("inlineCode",{parentName:"p"},"Detectron2")," and then ",(0,i.kt)("inlineCode",{parentName:"p"},"fairseq")),(0,i.kt)("p",null,"TODO: This needs better setup"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"sudo chown greg:greg /var/log/marie/\nsudo mkdir -p /var/log/marie\n")),(0,i.kt)("h3",{id:"marie-ai-as-a-dependency"},"Marie-AI as a dependency"),(0,i.kt)("p",null,"If you use Marie-AI as a dependency or third-party package, install it with pip:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"pip install 'marie-ai>=2.4.0'\n")),(0,i.kt)("h3",{id:"verify-the-installation"},"Verify the installation"),(0,i.kt)("p",null,"We provide a method to verify the installation via inference demo, depending on your installation method."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"TODO GRADIO LINK \n")),(0,i.kt)("p",null,"Also, you can run the following codes in your Python interpreter:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'from marie.executor import NerExtractionExecutor\nfrom marie.utils.image_utils import hash_file\n\n# setup executor\nmodels_dir = "/mnt/data/models/"\nexecutor = NerExtractionExecutor(models_dir)\n\nimg_path = "/tmp/sample.png"\nchecksum = hash_file(img_path)\n\n# invoke executor\ndocs = None\nkwa = {"checksum": checksum, "img_path": img_path}\nresults = executor.extract(docs, **kwa)\n\nprint(results)\n')),(0,i.kt)("h2",{id:"docker-image"},"Docker image"),(0,i.kt)("p",null,"Our universal Docker image is ready-to-use on linux/amd64 ",(0,i.kt)("a",{parentName:"p",href:"https://hub.docker.com/u/marieai"},"Image listing"),".\nThe Docker image name always starts with ",(0,i.kt)("inlineCode",{parentName:"p"},"marieai/marie")," followed by a tag composed of three parts:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-text"},"marieai/marie:{version}{python_version}{extra}\n")),(0,i.kt)("p",null,"nvidia/cuda:11.3.1-runtime-ubuntu20.04 "),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"{version}"),": The version of MarieAI. Possible values:",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"latest"),": the last release;"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"master"),": the master branch of ",(0,i.kt)("inlineCode",{parentName:"li"},"gregbugaj/marie-ai")," repository;"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"x.y.z"),": the release of a particular version; "))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"{python_version}"),": The Python version of the image. Possible values:",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"-py38")," for Python 3.8;"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"-py39")," for Python 3.9;"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"-py310")," for Python 3.10;"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"{extra}"),": the extra dependency installed along with MarieAI. Possible values:",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"-perf"),": MarieAI is installed inside the image via ",(0,i.kt)("inlineCode",{parentName:"li"},"pip install marieai"),". It includes all performance dependencies; "),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"-standard"),": MarieAI is installed inside the image via ",(0,i.kt)("inlineCode",{parentName:"li"},"pip install marieai"),". It includes all recommended dependencies;  "),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"-devel"),": MarieAI is installed inside the image via ",(0,i.kt)("inlineCode",{parentName:"li"},'pip install "marieai[devel]"'),". It includes ",(0,i.kt)("inlineCode",{parentName:"li"},"standard")," plus some extra dependencies;"))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"{env}"),": GPU/CPU/XLA support:",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"}," "),": CPU only; "),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"-cuda"),": MarieAI is build with GPU/CUDA support;  ")))),(0,i.kt)("h2",{id:"docker-on-cpu-only-platforms"},"Docker on CPU-only platforms"),(0,i.kt)("p",null,"MarieAI can be built for CPU-only environment. In CPU mode you can train, test or inference a model.\nHowever, there might be limitations of what operations can be used."),(0,i.kt)("h3",{id:"building-container"},"Building container"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"DOCKER_BUILDKIT=1 docker build . -f Dockerfiles/cpu.Dockerfile -t marieai/marie:2.5 --no-cache\n")),(0,i.kt)("h2",{id:"docker-with-gpu-support"},"Docker with GPU Support"),(0,i.kt)("h3",{id:"inference-on-the-gpu"},"Inference on the GPU"),(0,i.kt)("p",null,"Install following dependencies to ensure docker is setup for GPU processing."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://docs.nvidia.com/ai-enterprise/deployment-guide/dg-docker.html"},"Installing Docker and The Docker Utility Engine for NVIDIA GPUs")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html"},"NVIDIA Container Toolkit"))),(0,i.kt)("p",null,"After the installation we can validate the setup with :"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://hub.docker.com/r/nvidia/cuda/tags?page=2&ordering=last_updated&name=11.3"},"CUDA and cuDNN images from gitlab.com/nvidia/cuda")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"#### Test nvidia-smi with the official CUDA image\ndocker run --gpus all nvidia/cuda:11.3.1-runtime-ubuntu20.04 nvidia-smi\ndocker run --gpus all --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 nvidia/cuda:11.3.1-runtime-ubuntu20.04 nvidia-smi\n")),(0,i.kt)("h3",{id:"building-container-1"},"Building container"),(0,i.kt)("p",null,"If we have properly configured our environment you should be able to build the container locally."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},'DOCKER_BUILDKIT=1 docker build . --build-arg PIP_TAG="[standard]" -f ./Dockerfiles/gpu.Dockerfile  -t marieai/marie:3.0-cuda --no-cache\n')),(0,i.kt)("p",null,"After container have been build we can test it with following. "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"docker run --rm -it marieai/marie:3.0-cuda -vf\n")),(0,i.kt)("h2",{id:"container-maintenance"},"Container maintenance"),(0,i.kt)("p",null,"Marie comes with number of utilities for managing the containers. "),(0,i.kt)("admonition",{type:"note"},(0,i.kt)("p",{parentName:"admonition"},"When deployed with ",(0,i.kt)("a",{parentName:"p",href:"/docs/getting-started/deployment/control-plane#kubernetes"},"Kubernetes Control Plane"),",\nsome of  will be redundant.")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-text"},"(marie) greg@xpredator:~/dev/marie-ai$ tree docker-util/\ndocker-util/\n\u251c\u2500\u2500 container.sh\n\u251c\u2500\u2500 destroy.sh\n\u251c\u2500\u2500 exec.sh\n\u251c\u2500\u2500 id\n\u251c\u2500\u2500 id.github\n\u251c\u2500\u2500 monitor.sh\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 restart.sh\n\u251c\u2500\u2500 run-all.sh\n\u251c\u2500\u2500 run-interactive-cpu.sh\n\u251c\u2500\u2500 run-interactive-gpu.sh\n\u251c\u2500\u2500 run.sh\n\u251c\u2500\u2500 service.env\n\u251c\u2500\u2500 stop.sh\n\u251c\u2500\u2500 tail-log.sh\n\u251c\u2500\u2500 update.sh\n\u2514\u2500\u2500 version.sh\n\n")),(0,i.kt)("table",null,(0,i.kt)("thead",{parentName:"table"},(0,i.kt)("tr",{parentName:"thead"},(0,i.kt)("th",{parentName:"tr",align:null},"Feature"),(0,i.kt)("th",{parentName:"tr",align:null},"Interactive"),(0,i.kt)("th",{parentName:"tr",align:null},"Description"))),(0,i.kt)("tbody",{parentName:"table"},(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"container.sh"),(0,i.kt)("td",{parentName:"tr",align:null},"No"),(0,i.kt)("td",{parentName:"tr",align:null},"Display container information from ",(0,i.kt)("inlineCode",{parentName:"td"},"id")," file")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"destroy.sh"),(0,i.kt)("td",{parentName:"tr",align:null},"Yes"),(0,i.kt)("td",{parentName:"tr",align:null},"Destroy currently installed container and remove image")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"exec.sh"),(0,i.kt)("td",{parentName:"tr",align:null},"No"),(0,i.kt)("td",{parentName:"tr",align:null},"Login into current container")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"id"),(0,i.kt)("td",{parentName:"tr",align:null},"No"),(0,i.kt)("td",{parentName:"tr",align:null},(0,i.kt)("strong",{parentName:"td"},"ID")," file describing  the container")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"monitor.sh"),(0,i.kt)("td",{parentName:"tr",align:null},"No"),(0,i.kt)("td",{parentName:"tr",align:null},"Docker container monitoring via cAdvisor, DCGM-Exporter, Grafana Loki and Promtail  (convert to docker-compose)")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"restart.sh"),(0,i.kt)("td",{parentName:"tr",align:null},"No"),(0,i.kt)("td",{parentName:"tr",align:null},"Restart all containers")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"run-all.sh"),(0,i.kt)("td",{parentName:"tr",align:null},"No"),(0,i.kt)("td",{parentName:"tr",align:null},"Run all containers")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"run-interactive-cpu.sh"),(0,i.kt)("td",{parentName:"tr",align:null},"Yes"),(0,i.kt)("td",{parentName:"tr",align:null},"Run CPU container in interactive mode")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"run-interactive-gpu.sh"),(0,i.kt)("td",{parentName:"tr",align:null},"Yes"),(0,i.kt)("td",{parentName:"tr",align:null},"Run GPU container in interactive mode. Start container with GPU-ID 0 ",(0,i.kt)("inlineCode",{parentName:"td"},"./run-interactive-gpu.sh 0"))),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"stop.sh"),(0,i.kt)("td",{parentName:"tr",align:null},"No"),(0,i.kt)("td",{parentName:"tr",align:null},"Stop all containers")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"tail-log.sh"),(0,i.kt)("td",{parentName:"tr",align:null},"No"),(0,i.kt)("td",{parentName:"tr",align:null},"Tail logs from console")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"update.sh"),(0,i.kt)("td",{parentName:"tr",align:null},"No"),(0,i.kt)("td",{parentName:"tr",align:null},"Update container to version specified in ",(0,i.kt)("inlineCode",{parentName:"td"},"id")," file")),(0,i.kt)("tr",{parentName:"tbody"},(0,i.kt)("td",{parentName:"tr",align:null},"version.sh"),(0,i.kt)("td",{parentName:"tr",align:null},"No"),(0,i.kt)("td",{parentName:"tr",align:null},"Display ",(0,i.kt)("inlineCode",{parentName:"td"},"marie-ai"),"  version")))),(0,i.kt)("admonition",{title:"Security/Audit",type:"note"},(0,i.kt)("ul",{parentName:"admonition"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"This script must not be run as root, run under 'docker user' account.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Scripts will redirect the output of the current script to the system logger. "))),(0,i.kt)("pre",{parentName:"admonition"},(0,i.kt)("code",{parentName:"pre",className:"language-shell"},'exec 1> >(exec logger -s -t "${CONTAINER_NAME} [${0##*/}]") 2>&1\necho " container : ${CONTAINER_NAME}"\n'))),(0,i.kt)("h3",{id:"useful-docker-commands"},"Useful docker commands"),(0,i.kt)("p",null,"Stop running ",(0,i.kt)("inlineCode",{parentName:"p"},"marie-ai")," containers and remove volumes"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"docker container stop $(docker container ls -q --filter name='marie*') && docker system prune -af --volumes\n")),(0,i.kt)("p",null,"Tail logs"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"docker logs  marie-icr-0  -f --since 0m\n")),(0,i.kt)("h2",{id:"common-issues"},"Common issues"),(0,i.kt)("h3",{id:"segmentation-fault"},"Segmentation fault"),(0,i.kt)("p",null,"There is a segmentation fault happening with ",(0,i.kt)("inlineCode",{parentName:"p"},"opencv-python==4.5.4.62")," switching to ",(0,i.kt)("inlineCode",{parentName:"p"},"opencv-python==4.5.4.60")," fixes the issue.\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/opencv/opencv-python/issues/604"},"connectedComponentsWithStats produces a segfault ")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"pip install opencv-python==4.5.4.60\n")),(0,i.kt)("h3",{id:"missing-convert_namespace_to_omegaconf"},"Missing convert_namespace_to_omegaconf"),(0,i.kt)("p",null,"Install ",(0,i.kt)("inlineCode",{parentName:"p"},"fairseq")," from source, the release version is  missing ",(0,i.kt)("inlineCode",{parentName:"p"},"convert_namespace_to_omegaconf")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/pytorch/fairseq.git\ncd fairseq\npip install -r requirements.txt\npython setup.py build develop\n")),(0,i.kt)("h3",{id:"distutils-has-no-attribute-version"},(0,i.kt)("inlineCode",{parentName:"h3"},"distutils")," has no attribute version"),(0,i.kt)("p",null,"If you receive following error :"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"AttributeError: module 'distutils' has no attribute 'version'\n")),(0,i.kt)("p",null,"Using following version of ",(0,i.kt)("inlineCode",{parentName:"p"},"setuptools")," will work."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},"python3 -m pip install setuptools==59.5.0\n")),(0,i.kt)("h3",{id:"cuda-capability-sm_86-is-not-compatible-with-the-current-pytorch-installation"},"CUDA capability sm_86 is not compatible with the current PyTorch installation"),(0,i.kt)("p",null,"Building GPU version of the framework requires ",(0,i.kt)("inlineCode",{parentName:"p"},"1.10.2+cu113"),". "),(0,i.kt)("p",null,"If you encounter following error that indicates that we have a wrong version of PyTorch / Cuda"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre"},'1.11.0+cu102\nUsing device: cuda\n\n/opt/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:145: UserWarning: \nNVIDIA GeForce RTX 3060 Laptop GPU with CUDA capability sm_86 is not compatible with the current PyTorch installation.\nThe current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\nIf you want to use the NVIDIA GeForce RTX 3060 Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n\n  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))\n\n')),(0,i.kt)("h3",{id:"references"},"References"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://docs.docker.com/get-started/overview/"},"Docker overview")),(0,i.kt)("p",null,"1216"))}c.isMDXComponent=!0}}]);
"use strict";(self.webpackChunkmare_ai=self.webpackChunkmare_ai||[]).push([[417],{3905:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>u});var n=r(7294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function a(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},i=Object.keys(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var p=n.createContext({}),s=function(e){var t=n.useContext(p),r=t;return e&&(r="function"==typeof e?e(t):a(a({},t),e)),r},c=function(e){var t=s(e.components);return n.createElement(p.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,i=e.originalType,p=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=s(r),u=o,f=d["".concat(p,".").concat(u)]||d[u]||m[u]||i;return r?n.createElement(f,a(a({ref:t},c),{},{components:r})):n.createElement(f,a({ref:t},c))}));function u(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=r.length,a=new Array(i);a[0]=d;var l={};for(var p in t)hasOwnProperty.call(t,p)&&(l[p]=t[p]);l.originalType=e,l.mdxType="string"==typeof e?e:o,a[1]=l;for(var s=2;s<i;s++)a[s]=r[s];return n.createElement.apply(null,a)}return n.createElement.apply(null,r)}d.displayName="MDXCreateElement"},8263:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>p,contentTitle:()=>a,default:()=>m,frontMatter:()=>i,metadata:()=>l,toc:()=>s});var n=r(7462),o=(r(7294),r(3905));const i={sidebar_position:3},a="Optimizing models for inference with ONNX",l={unversionedId:"getting-started/inference/onnx",id:"getting-started/inference/onnx",title:"Optimizing models for inference with ONNX",description:"Marie-AI supports the ONNX format for inference. ONNX is an open format for machine learning models that allows you to easily move models between different frameworks.",source:"@site/docs/getting-started/inference/onnx.md",sourceDirName:"getting-started/inference",slug:"/getting-started/inference/onnx",permalink:"/docs/getting-started/inference/onnx",draft:!1,editUrl:"https://github.com/gregbugaj/marie-ai/tree/develop/docs/docs/getting-started/inference/onnx.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"tutorialSidebar",previous:{title:"Inference",permalink:"/docs/category/inference"},next:{title:"Fundamentals",permalink:"/docs/category/fundamentals"}},p={},s=[{value:"TensorRT support",id:"tensorrt-support",level:2},{value:"Setup",id:"setup",level:3},{value:"Optimize Pix2Pix models export for document overlay",id:"optimize-pix2pix-models-export-for-document-overlay",level:2},{value:"Requirement",id:"requirement",level:2},{value:"Install fairseq and requirement",id:"install-fairseq-and-requirement",level:3}],c={toc:s};function m(e){let{components:t,...r}=e;return(0,o.kt)("wrapper",(0,n.Z)({},c,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"optimizing-models-for-inference-with-onnx"},"Optimizing models for inference with ONNX"),(0,o.kt)("p",null,"Marie-AI supports the ",(0,o.kt)("a",{parentName:"p",href:"https://onnx.ai/"},"ONNX")," format for inference. ONNX is an open format for machine learning models that allows you to easily move models between different frameworks. "),(0,o.kt)("h1",{id:"exporting-models-to-onnx"},"Exporting models to ONNX"),(0,o.kt)("p",null,"There are many ways to export models to ONNX. Here we will show you how to export our PyTorch model to ONNX."),(0,o.kt)("h2",{id:"tensorrt-support"},"TensorRT support"),(0,o.kt)("p",null,"TensorRT is a high-performance deep learning inference platform that delivers low latency and high-throughput for deep learning inference applications."),(0,o.kt)("h3",{id:"setup"},"Setup"),(0,o.kt)("p",null,"We need to setup the environment to support TensorRT. "),(0,o.kt)("h2",{id:"optimize-pix2pix-models-export-for-document-overlay"},"Optimize Pix2Pix models export for document overlay"),(0,o.kt)("p",null,"In the tools directory we have a script that will export the Pix2Pix model to ONNX. "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sh"},"python3 tools/convert_onnx_overlay.py \\\n    --model_path /mnt/data/marie-ai/model_zoo/pix2pix/pix2pix.pth \\\n    --output_path /mnt/data/marie-ai/model_zoo/pix2pix/pix2pix.onnx\n")),(0,o.kt)("h1",{id:"optimize-fairseq-models-for-ocr"},"Optimize Fairseq models for OCR"),(0,o.kt)("p",null,"Fairseq is used by Marie-AI for OCR as it is based on the TrOCR model."),(0,o.kt)("p",null,"We have a custom build of Fairseq that supports ONNX export and inference.\nYou can find the source code ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/marieai/fairseq"},"here")),(0,o.kt)("p",null,"To optimize Fairseq workflow we have to do the following:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"Divide model into Encoder and Decoder two parts, and separately export to onnx model.\n"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"Because of the model structure define by input seq_len, should export dynamic shape onnx model.\n"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"Replace the Fairseq TextRecognitionGenerator task pipeline Encoder and Decoder into ONNX inference model.\n")))),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Encoder and Decoder:")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Encoder is for extracting feature information from image."),(0,o.kt)("li",{parentName:"ul"},"Decoder is for decoding the feature information to generate text information.")),(0,o.kt)("h2",{id:"requirement"},"Requirement"),(0,o.kt)("p",null,"Checkout the source code and install the package in editable mode.\nReference: ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/marieai/fairseq.git"},"GitHub: Fairseq-MarieAI")),(0,o.kt)("h3",{id:"install-fairseq-and-requirement"},"Install fairseq and requirement"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sh"},"git clone https://github.com/marieai/fairseq.git\ncd fairseq\npip install --editable .\n")),(0,o.kt)("p",null,"Edit ",(0,o.kt)("inlineCode",{parentName:"p"},"sequence_generator.py")," to apply changes to the source code."),(0,o.kt)("h1",{id:"references"},"References"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://onnx.ai/"},"ONNX")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://developer.nvidia.com/tensorrt"},"TensorRT")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://blog.openvino.ai/blog-posts/openvino-tm-optimizer-fairseq-s2t-model"},"openvino"))),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://github.com/facebookresearch/fairseq/issues/1669"},"https://github.com/facebookresearch/fairseq/issues/1669"),"\n",(0,o.kt)("a",{parentName:"p",href:"https://github.com/18582088138/fairseq-openvino/blob/bc61ffe59ae79870815d34d2664a9fffe6d9c694/fairseq/sequence_generator.py"},"https://github.com/18582088138/fairseq-openvino/blob/bc61ffe59ae79870815d34d2664a9fffe6d9c694/fairseq/sequence_generator.py")))}m.isMDXComponent=!0}}]);